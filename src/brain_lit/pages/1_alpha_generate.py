import os
import sys

import streamlit as st

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„ä¸­
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from brain_lit.logger import setup_logger
from brain_lit.sidebar import render_sidebar
from brain_lit.svc.dataset import get_all_datasets, get_used_datasets
from brain_lit.svc.alpha_query import query_alphas_by_conditions, query_alphas_simulation_stats

# è®¾ç½®logger
logger = setup_logger()

# æ¸²æŸ“å…±äº«çš„ä¾§è¾¹æ 
render_sidebar()

def get_selected_dataset_ids():
    """è·å–å½“å‰é€‰ä¸­çš„æ•°æ®é›†åˆ—è¡¨"""
    selected_datasets = []
    for key in st.session_state:
        if key.startswith("selected_dataset_"):
            dataset_info = st.session_state[key]
            if isinstance(dataset_info, dict):
                dataset_id = dataset_info.get("id", "")
            else:
                dataset_id = dataset_info
            selected_datasets.append(dataset_id)
    return selected_datasets

st.title("ğŸ“ˆ ç”ŸæˆAlpha")

# ä¸»è¦å†…å®¹åŒºåŸŸ
# st.markdown("åœ¨æœ¬é¡µé¢æ‚¨å¯ä»¥ç”Ÿæˆæ–°çš„Alphaè¡¨è¾¾å¼ã€‚")

# åˆå§‹åŒ–session stateä¸­çš„å‚æ•°
if "current_page" not in st.session_state:
    st.session_state.current_page = 1

# åˆå§‹åŒ–ç¼“å­˜
if "cached_datasets" not in st.session_state:
    st.session_state.cached_datasets = {}

# åˆå§‹åŒ–ç­›é€‰çŠ¶æ€
if "show_only_unused" not in st.session_state:
    st.session_state.show_only_unused = False

if "show_only_unused_prev" not in st.session_state:
    st.session_state.show_only_unused_prev = False

# åˆå§‹åŒ–"ä¸»é¢˜ä¹˜æ•°éç©º"ç­›é€‰çŠ¶æ€
if "filter_non_empty_themes" not in st.session_state:
    st.session_state.filter_non_empty_themes = False

if "filter_non_empty_themes_prev" not in st.session_state:
    st.session_state.filter_non_empty_themes_prev = False

# ä»session stateè·å–å·²é€‰æ‹©çš„å‚æ•°
selected_region = st.session_state.selected_region
selected_universe = st.session_state.selected_universe
selected_delay = st.session_state.selected_delay
selected_category = st.session_state.selected_category

# æ•°æ®é›†é€‰æ‹©éƒ¨åˆ†
# åˆ›å»ºä¸€è¡Œæ¥æ”¾ç½®æ ‡é¢˜å’Œæ§ä»¶
title_col, unused_col, theme_col, button_col = st.columns([4, 1, 1, 1])

with title_col:
    st.subheader("æ•°æ®é›†é€‰æ‹©")

with unused_col:
    # è·å–å½“å‰çš„checkboxçŠ¶æ€
    current_show_only_unused = st.checkbox(
        "æœªä½¿ç”¨è¿‡",
        value=st.session_state.get("show_only_unused", False),
        key="show_only_unused_checkbox"
    )
    # æ›´æ–°session state
    st.session_state.show_only_unused = current_show_only_unused
    # å½“ç­›é€‰çŠ¶æ€æ”¹å˜æ—¶é‡ç½®é¡µç 
    if current_show_only_unused != st.session_state.get("show_only_unused_prev", False):
        st.session_state.current_page = 1
        st.session_state.show_only_unused_prev = current_show_only_unused
        if st.session_state.get("query_datasets_clicked", False):
            st.rerun()

with theme_col:
    # æ·»åŠ "ä¸»é¢˜ä¹˜æ•°éç©º"è¿‡æ»¤é€‰é¡¹
    current_filter_non_empty_themes = st.checkbox(
        "ä¸»é¢˜éç©º",
        value=st.session_state.get("filter_non_empty_themes", False),
        key="filter_non_empty_themes_checkbox"
    )
    # æ›´æ–°session state
    st.session_state.filter_non_empty_themes = current_filter_non_empty_themes
    # å½“ç­›é€‰çŠ¶æ€æ”¹å˜æ—¶é‡ç½®é¡µç 
    if current_filter_non_empty_themes != st.session_state.get("filter_non_empty_themes_prev", False):
        st.session_state.current_page = 1
        st.session_state.filter_non_empty_themes_prev = current_filter_non_empty_themes
        if st.session_state.get("query_datasets_clicked", False):
            st.rerun()

with button_col:
    # æ·»åŠ æŸ¥è¯¢æ•°æ®é›†æŒ‰é’®
    if st.button("æŸ¥è¯¢æ•°æ®é›†"):
        st.session_state.query_datasets_clicked = True

# åªæœ‰å½“æŸ¥è¯¢æŒ‰é’®è¢«ç‚¹å‡»æ—¶æ‰ç»§ç»­æ‰§è¡Œæ•°æ®é›†æŸ¥è¯¢å’Œæ˜¾ç¤ºé€»è¾‘
if st.session_state.get("query_datasets_clicked", False):
    # å½“å‚æ•°å‘ç”Ÿå˜åŒ–æ—¶é‡ç½®é¡µç 
    params_changed = (
        selected_region != st.session_state.get('prev_region', selected_region) or 
        selected_universe != st.session_state.get('prev_universe', selected_universe) or 
        selected_delay != st.session_state.get('prev_delay', selected_delay) or
        selected_category != st.session_state.get('prev_category', selected_category)
    )

    if params_changed:
        st.session_state.current_page = 1
        # å‚æ•°å˜åŒ–æ—¶æ¸…é™¤ç¼“å­˜
        cache_keys_to_remove = [key for key in st.session_state.cached_datasets.keys() 
                               if key.startswith(f"{selected_region}_{selected_universe}_{selected_delay}")]
        for key in cache_keys_to_remove:
            del st.session_state.cached_datasets[key]

    # ä¿å­˜å½“å‰å‚æ•°ä»¥ä¾¿ä¸‹æ¬¡æ¯”è¾ƒ
    st.session_state.prev_region = selected_region
    st.session_state.prev_universe = selected_universe
    st.session_state.prev_delay = selected_delay
    st.session_state.prev_category = selected_category

    # åˆ†é¡µæ˜¾ç¤ºæ•°æ®é›†
    session = st.session_state.global_session

    # æ„å»ºAPIè¯·æ±‚å‚æ•°
    dataset_params = {
        "region": selected_region,
        "universe": selected_universe,
        "delay": selected_delay,
        "instrumentType": "EQUITY",
    }

    # æ·»åŠ åˆ†ç±»å‚æ•°ï¼ˆå¦‚æœä¸æ˜¯"All"ï¼‰
    if selected_category and selected_category != "All":
        dataset_params["category"] = selected_category

    # ç”Ÿæˆç¼“å­˜é”®
    cache_key = f"{selected_region}_{selected_universe}_{selected_delay}_{selected_category}_all"

    # è·å–æ•°æ®é›†åˆ—è¡¨
    with st.spinner("æ­£åœ¨è·å–æ•°æ®é›†åˆ—è¡¨..."):
        # æ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜çš„æ•°æ®
        if cache_key in st.session_state.cached_datasets:
            all_datasets, total_count = st.session_state.cached_datasets[cache_key]
        else:
            # è·å–æ‰€æœ‰æ•°æ®é›†
            all_datasets, total_count = get_all_datasets(session, dataset_params)
            # ç¼“å­˜æ•°æ®
            st.session_state.cached_datasets[cache_key] = (all_datasets, total_count)

    datasets = all_datasets

    # æ˜¾ç¤ºæ•°æ®é›†é€‰æ‹©
    if datasets:
        # è·å–å·²ä½¿ç”¨çš„æ•°æ®é›†åˆ—è¡¨ï¼ˆä¸€æ¬¡æ€§è·å–ï¼Œé¿å…é‡å¤æŸ¥è¯¢æ•°æ®åº“ï¼‰
        used_datasets = get_used_datasets(selected_region, selected_universe, selected_delay)
        
        # è¿‡æ»¤å·²ä½¿ç”¨çš„æ•°æ®é›†ï¼ˆå¦‚æœç”¨æˆ·é€‰æ‹©äº†åªæ˜¾ç¤ºæœªä½¿ç”¨çš„æ•°æ®é›†ï¼‰
        show_only_unused = st.session_state.get("show_only_unused", False)
        filter_non_empty_themes = st.session_state.get("filter_non_empty_themes", False)
        
        # åº”ç”¨ç­›é€‰æ¡ä»¶
        filtered_datasets = datasets
        
        # è¿‡æ»¤å·²ä½¿ç”¨çš„æ•°æ®é›†
        if show_only_unused:
            filtered_datasets = [
                dataset for dataset in filtered_datasets 
                if not (
                    dataset.get("id", "") if isinstance(dataset, dict) else dataset
                ) in used_datasets
            ]
        
        # è¿‡æ»¤ä¸»é¢˜ä¹˜æ•°éç©ºçš„æ•°æ®é›†
        if filter_non_empty_themes:
            filtered_datasets = [
                dataset for dataset in filtered_datasets
                if isinstance(dataset, dict) and "themes" in dataset and dataset["themes"] and 
                   any(theme.get("multiplier") is not None for theme in dataset["themes"])
            ]
        
        # è®¡ç®—è¿‡æ»¤åçš„æ•°æ®é›†æ•°é‡
        filtered_count = len(filtered_datasets)
        
        # è®¡ç®—æ€»é¡µæ•°
        page_size = 20  # æ¯é¡µæ˜¾ç¤ºçš„æ•°æ®æ¡æ•°
        if show_only_unused:
            total_pages = (filtered_count + page_size - 1) // page_size if filtered_count > 0 else 1
            display_count = filtered_count
        else:
            total_pages = (total_count + page_size - 1) // page_size if total_count > 0 else 1
            display_count = total_count
        
        # ç¡®ä¿å½“å‰é¡µç åœ¨æœ‰æ•ˆèŒƒå›´å†…
        if st.session_state.current_page > total_pages:
            st.session_state.current_page = total_pages
        if st.session_state.current_page < 1:
            st.session_state.current_page = 1
        
        # åœ¨åŒä¸€è¡Œæ˜¾ç¤ºæ•°æ®é›†æ€»æ•°ã€ç­›é€‰é€‰é¡¹å’Œåˆ†é¡µæ§ä»¶
        count_col, prev_col, info_col, next_col = st.columns([4, 1, 1, 1])
        with count_col:
            if show_only_unused:
                st.write(f"å…±æ‰¾åˆ° {filtered_count} ä¸ªæœªä½¿ç”¨æ•°æ®é›†ï¼ˆæ€»è®¡ {total_count} ä¸ªï¼‰")
            else:
                st.write(f"å…±æ‰¾åˆ° {total_count} ä¸ªæ•°æ®é›†")
        with prev_col:
            if st.button("ä¸Šä¸€é¡µ", disabled=(st.session_state.current_page <= 1)):
                st.session_state.current_page -= 1
                st.rerun()
        with info_col:
            st.write(f"ç¬¬ {st.session_state.current_page} é¡µï¼Œå…± {total_pages} é¡µ")
        with next_col:
            if st.button("ä¸‹ä¸€é¡µ", disabled=(st.session_state.current_page >= total_pages)):
                st.session_state.current_page += 1
                st.rerun()
        
        # æ˜¾ç¤ºè¡¨æ ¼å½¢å¼çš„æ•°æ®é›†
        # åˆ›å»ºè¡¨æ ¼æ ‡é¢˜è¡Œ
        header_cols = st.columns([1, 2, 2, 1, 1, 1, 1, 1, 1, 1])
        headers = ["é€‰æ‹©", "ID", "åˆ†ç±»", "ä¸»é¢˜ä¹˜æ•°", "è¦†ç›–ç‡", "ä»·å€¼è¯„åˆ†", "ç”¨æˆ·æ•°", "Alphaæ•°", "å­—æ®µæ•°", "é‡‘å­—å¡”ä¹˜æ•°"]
        
        for col, header in zip(header_cols, headers):
            col.write(f"**{header}**")
        
        # è®¡ç®—å½“å‰é¡µåº”è¯¥æ˜¾ç¤ºçš„æ•°æ®
        start_idx = (st.session_state.current_page - 1) * page_size
        end_idx = min(start_idx + page_size, len(filtered_datasets))
        page_datasets = filtered_datasets[start_idx:end_idx]
        
        # æ˜¾ç¤ºæ•°æ®è¡Œ
        for dataset in page_datasets:
            # ç¡®ä¿datasetæ˜¯å­—å…¸ç±»å‹
            if isinstance(dataset, str):
                dataset_id = dataset
                dataset_dict = {"id": dataset_id}
            else:
                dataset_dict = dataset
                dataset_id = dataset_dict.get("id", "")
                
            # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦å·²è¢«ä½¿ç”¨
            used = dataset_id in used_datasets
            
            # å¤„ç†themeså­—æ®µï¼Œæ˜¾ç¤ºmultiplierå€¼è€Œä¸æ˜¯nameå€¼
            themes_multiplier = ""
            if isinstance(dataset_dict, dict) and "themes" in dataset_dict:
                themes_multiplier = ", ".join([str(theme.get("multiplier", "")) for theme in dataset_dict.get("themes", [])]) if dataset_dict.get("themes") else ""
            
            # åˆ›å»ºæ•°æ®è¡Œ
            cols = st.columns([1, 2, 2, 1, 1, 1, 1, 1, 1, 1])
            
            # å¤é€‰æ¡†
            with cols[0]:
                is_selected = st.checkbox(
                    f"é€‰æ‹©æ•°æ®é›† {dataset_id}", 
                    key=f"select_{dataset_id}",
                    value=st.session_state.get(f"selected_dataset_{dataset_id}", False),
                    label_visibility="collapsed"
                )
                # æ›´æ–°session state
                if is_selected:
                    st.session_state[f"selected_dataset_{dataset_id}"] = dataset_dict
                elif f"selected_dataset_{dataset_id}" in st.session_state:
                    del st.session_state[f"selected_dataset_{dataset_id}"]
            
            # æ•°æ®é›†IDåˆ— - å¯¹å·²ä½¿ç”¨çš„æ•°æ®é›†ä½¿ç”¨ç‰¹æ®Šæ ‡è®°
            with cols[1]:
                if used:
                    # ä½¿ç”¨ç‰¹æ®Šé¢œè‰²å’Œæ ‡è®°æ¥æ ‡è¯†å·²ä½¿ç”¨çš„æ•°æ®é›†
                    st.markdown(f"<span style='color: #1f77b4; font-weight: bold;'>{dataset_id} ğŸ”µ</span>", unsafe_allow_html=True)
                else:
                    st.write(dataset_id)
            
            # å…¶ä»–æ•°æ®åˆ—
            category_name = ""
            if isinstance(dataset_dict, dict) and "category" in dataset_dict:
                category_data = dataset_dict.get("category", {})
                if isinstance(category_data, dict):
                    category_name = category_data.get("name", "")
                else:
                    category_name = str(category_data)
            
            coverage = 0.0
            if isinstance(dataset_dict, dict):
                coverage = dataset_dict.get("coverage", 0.0)
                
            value_score = 0
            if isinstance(dataset_dict, dict):
                value_score = dataset_dict.get("valueScore", 0)
                
            user_count = 0
            if isinstance(dataset_dict, dict):
                user_count = dataset_dict.get("userCount", 0)
                
            alpha_count = 0
            if isinstance(dataset_dict, dict):
                alpha_count = dataset_dict.get("alphaCount", 0)
                
            field_count = 0
            if isinstance(dataset_dict, dict):
                field_count = dataset_dict.get("fieldCount", 0)
                
            pyramid_multiplier = ""
            if isinstance(dataset_dict, dict):
                pyramid_multiplier = dataset_dict.get("pyramidMultiplier", "")
            
            cols[2].write(category_name)
            cols[3].write(themes_multiplier)
            cols[4].write(f"{coverage:.2%}")
            cols[5].write(value_score)
            cols[6].write(user_count)
            cols[7].write(alpha_count)
            cols[8].write(field_count)
            cols[9].write(pyramid_multiplier)
                    
    else:
        st.info("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ‰¾åˆ°æ•°æ®é›†")
        st.session_state.current_page = 1

# Alphaè¡¨è¾¾å¼è¾“å…¥åŒºåŸŸ
st.subheader("Alphaè¡¨è¾¾å¼")
alpha_expression = st.text_area(
    "è¯·è¾“å…¥æ‚¨çš„Alphaè¡¨è¾¾å¼:",
    height=200,
    placeholder="# ç¤ºä¾‹Alphaè¡¨è¾¾å¼\n# rank(correlation(close, returns, 5))"
)

# å‚æ•°è®¾ç½®
st.subheader("å‚æ•°è®¾ç½®")
col1, col2, col3 = st.columns(3)

with col1:
    neutralization = st.selectbox(
        "ä¸­æ€§åŒ–é€‰é¡¹",
        ["SIZE", "SECTOR", "VOLATILITY", "LIQUIDITY", "MOMENTUM"]
    )

with col2:
    decay = st.number_input("è¡°å‡å¤©æ•°", min_value=1, max_value=30, value=5)

with col3:
    truncation = st.slider("æˆªæ–­ç™¾åˆ†æ¯”", 0.0, 10.0, 5.0, 0.1)

# æ“ä½œæŒ‰é’®
st.markdown("---")
col6, col7, col8, col9 = st.columns([1, 1, 1, 3])

with col6:
    if st.button("ç”ŸæˆAlpha", type="primary"):
        if alpha_expression.strip():
            st.success("Alphaè¡¨è¾¾å¼å·²æäº¤è¿›è¡Œå›æµ‹ï¼")
            st.session_state.pending_alpha = alpha_expression
            st.switch_page("pages/2_Simulate_Alpha.py")
        else:
            st.warning("è¯·è¾“å…¥Alphaè¡¨è¾¾å¼")

with col7:
    if st.button("æŸ¥è¯¢Alpha"):
        # è·å–å½“å‰é€‰ä¸­çš„æ•°æ®é›†
        selected_dataset_ids = get_selected_dataset_ids()
        
        # æŸ¥è¯¢Alphaè®°å½•
        query_results = query_alphas_by_conditions(
            selected_region,
            selected_universe,
            selected_delay,
            selected_category,
            selected_dataset_ids  # ä¼ å…¥é€‰ä¸­çš„æ•°æ®é›†IDåˆ—è¡¨
        )
        
        if query_results:
            st.session_state.query_results = query_results
            st.session_state.show_query_results = True
            st.rerun()
        else:
            st.info("æœªæ‰¾åˆ°ç›¸å…³çš„Alphaè®°å½•")

with col8:
    if st.button("ç»Ÿè®¡ä¿¡æ¯"):
        # è·å–å½“å‰é€‰ä¸­çš„æ•°æ®é›†
        selected_dataset_ids = get_selected_dataset_ids()
        
        # è·å–å¹¶æ˜¾ç¤ºæ¨¡æ‹ŸçŠ¶æ€ç»Ÿè®¡ä¿¡æ¯
        simulation_stats = query_alphas_simulation_stats(
            selected_region,
            selected_universe,
            selected_delay,
            selected_category,
            selected_dataset_ids  # ä¼ å…¥é€‰ä¸­çš„æ•°æ®é›†IDåˆ—è¡¨
        )
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        if simulation_stats:
            # ä¿å­˜ç»Ÿè®¡ä¿¡æ¯åˆ°session_stateï¼Œä½¿å…¶åœ¨å…¶ä»–æ“ä½œåä»ä¿æŒæ˜¾ç¤º
            st.session_state.simulation_stats_data = simulation_stats
        else:
            st.session_state.simulation_stats_data = None

with col9:
    if st.button("æ¸…ç©º"):
        st.rerun()

# æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ˆå¦‚æœå­˜åœ¨ä¸”æœªè¢«æ¸…é™¤ï¼‰
if st.session_state.get("simulation_stats_data"):
    # è®¡ç®—æ€»è®°å½•æ•°
    stats = st.session_state.simulation_stats_data
    if stats:
        
        # å‡†å¤‡ç”¨äºæ°´å¹³å †å æ¡å½¢å›¾çš„æ•°æ®
        import pandas as pd

        # è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(stats)

        # æ˜¾ç¤ºæ¡å½¢å›¾ï¼Œä½¿ç”¨simulatedåˆ—ä½œä¸ºé¢œè‰²åˆ†ç»„
        st.bar_chart(df, x="simulated", y="count", color="simulated", horizontal=True)
    else:
        st.info("æš‚æ— ç»Ÿè®¡æ•°æ®")

# æ˜¾ç¤ºæŸ¥è¯¢ç»“æœ
if st.session_state.get("show_query_results", False):
    st.subheader("æŸ¥è¯¢ç»“æœ")
    query_results = st.session_state.get("query_results", [])
    
    if query_results:
        # æ˜¾ç¤ºè®°å½•æ€»æ•°
        st.write(f"å…±æ‰¾åˆ° {len(query_results)} æ¡è®°å½•")
        
        # ä½¿ç”¨pandaså±•ç¤ºç»“æœ
        import pandas as pd
        
        # å‡†å¤‡æ•°æ®
        display_data = []
        for result in query_results:
            display_data.append({
                "Alphaè¡¨è¾¾å¼": str(result.get("alpha", ""))[:50] + "..." if len(str(result.get("alpha", ""))) > 50 else str(result.get("alpha", "")),
                "Sharp": result.get("sharp", ""),
                "Fitness": result.get("fitness", ""),
                "è¡°å‡": result.get("decay", ""),
                "ä¸­æ€§åŒ–": result.get("neutralization", ""),
                "é˜¶æ®µ": result.get("phase", ""),
                "æ›´æ–°æ—¶é—´": result.get("updated_at", "") if result.get("updated_at") else result.get("created_at", "")
            })
        
        # åˆ›å»ºDataFrameå¹¶æ˜¾ç¤º
        df = pd.DataFrame(display_data)
        st.dataframe(df, width='stretch')
    else:
        st.info("æœªæ‰¾åˆ°ç›¸å…³è®°å½•")

# æ˜¾ç¤ºç¤ºä¾‹
with st.expander("æŸ¥çœ‹Alphaè¡¨è¾¾å¼ç¤ºä¾‹"):
    st.markdown("""
    ### å¸¸ç”¨å‡½æ•°ç¤ºä¾‹:
    - `rank(correlation(close, returns, 5))`
    - `ts_mean(volume, 10) / ts_mean(volume, 30)`
    - `zscore(open / close)`
    
    ### å¯ç”¨æ“ä½œç¬¦:
    - åŸºæœ¬è¿ç®—: `+`, `-`, `*`, `/`, `**`
    - æ¯”è¾ƒè¿ç®—: `<`, `>`, `<=`, `>=`, `==`, `!=`
    - é€»è¾‘è¿ç®—: `&` (ä¸), `|` (æˆ–), `~` (é)
    """)